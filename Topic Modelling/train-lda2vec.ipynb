{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lda2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "0EQbWRaAUzUF",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import shelve\n",
    "import os.path\n",
    "import chainer\n",
    "\n",
    "import numpy as np\n",
    "import chainer.optimizers as O\n",
    "\n",
    "from chainer import cuda\n",
    "from lda2vec import utils\n",
    "from lda2vec import LDA2Vec\n",
    "from chainer import serializers\n",
    "from lda2vec import prepare_topics, print_top_words_per_topic, topic_coherence"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2G0gMxPmU68s",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "base_path = 'drive/My Drive/data-topic-modeling/'\n",
    "# Load Files\n",
    "fn_vocab = base_path + 'vocab.pkl'\n",
    "fn_corpus = base_path + 'corpus.pkl'\n",
    "fn_flatnd = base_path + 'flattened.npy'\n",
    "fn_docids = base_path + 'doc_ids.npy'\n",
    "fn_vectors = base_path + 'vectors.npy'\n",
    "vocab = pickle.load(open(fn_vocab, 'rb'))\n",
    "corpus = pickle.load(open(fn_corpus, 'rb'))\n",
    "flattened = np.load(fn_flatnd)\n",
    "doc_ids = np.load(fn_docids)\n",
    "vectors = np.load(fn_vectors)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UFf8ubQEV-1P",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "24cb0c53-6679-4e4e-a760-d15b69cb4523"
   },
   "source": [
    "gpu_id = int(os.getenv('CUDA_GPU', 0))\n",
    "cuda.get_device(gpu_id).use()\n",
    "print(\"Using GPU:\" + str(gpu_id))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using GPU:0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tz_taO5fWEMV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Model Parameters\n",
    "# Number of documents\n",
    "n_docs = doc_ids.max() + 1\n",
    "# Number of unique words in the vocabulary\n",
    "n_vocab = flattened.max() + 1\n",
    "# 'Strength' of the dircihlet prior; 200.0 seems to work well\n",
    "clambda = 200.0\n",
    "# Number of topics to fit\n",
    "n_topics = int(os.getenv('n_topics', 20))\n",
    "batchsize = 4096\n",
    "# Power for neg sampling\n",
    "power = float(os.getenv('power', 0.75))\n",
    "# Intialize with pretrained word vectors\n",
    "pretrained = bool(int(os.getenv('pretrained', True)))\n",
    "# Sampling temperature\n",
    "temperature = float(os.getenv('temperature', 1.0))\n",
    "# Number of dimensions in a single word vector\n",
    "n_units = int(os.getenv('n_units', 300))\n",
    "# Get the string representation for every compact key\n",
    "words = corpus.word_list(vocab)[:n_vocab]\n",
    "# How many tokens are in each document\n",
    "doc_idx, lengths = np.unique(doc_ids, return_counts=True)\n",
    "doc_lengths = np.zeros(doc_ids.max() + 1, dtype='int32')\n",
    "doc_lengths[doc_idx] = lengths\n",
    "# Count all token frequencies\n",
    "tok_idx, freq = np.unique(flattened, return_counts=True)\n",
    "term_frequency = np.zeros(n_vocab, dtype='int32')\n",
    "term_frequency[tok_idx] = freq"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cZA1DZbwWJXt",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "outputId": "40ff76fc-b523-4d89-b3f8-071f1862bd90"
   },
   "source": [
    "for key in sorted(locals().keys()):\n",
    "    val = locals()[key]\n",
    "    if len(str(val)) < 100 and '<' not in str(val):\n",
    "        print(key, val)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Out {}\n",
      "_ \n",
      "__ \n",
      "___ \n",
      "__doc__ Automatically created module for IPython interactive environment\n",
      "__loader__ None\n",
      "__name__ __main__\n",
      "__package__ None\n",
      "__spec__ None\n",
      "_dh ['/content']\n",
      "_exit_code 0\n",
      "_i1 !pip install pylda2vec\n",
      "_i2 !python -m spacy download en_core_web_md\n",
      "_i3 !pip install jellyfish\n",
      "_oh {}\n",
      "base_path drive/My Drive/data-topic-modeling/\n",
      "batchsize 4096\n",
      "clambda 200.0\n",
      "doc_ids [    0     0     0 ... 11008 11008 11008]\n",
      "doc_idx [    0     1     2 ... 11006 11007 11008]\n",
      "doc_lengths [100  92 333 ... 115  63  50]\n",
      "flattened [  10   38 1311 ...   50   50   50]\n",
      "fn_corpus drive/My Drive/data-topic-modeling/corpus.pkl\n",
      "fn_docids drive/My Drive/data-topic-modeling/doc_ids.npy\n",
      "fn_flatnd drive/My Drive/data-topic-modeling/flattened.npy\n",
      "fn_vectors drive/My Drive/data-topic-modeling/vectors.npy\n",
      "fn_vocab drive/My Drive/data-topic-modeling/vocab.pkl\n",
      "freq [105415 103788 100993 ...     30     30     29]\n",
      "gpu_id 0\n",
      "lengths [100  92 333 ... 115  63  50]\n",
      "n_docs 11009\n",
      "n_topics 20\n",
      "n_units 300\n",
      "n_vocab 5845\n",
      "power 0.75\n",
      "pretrained True\n",
      "temperature 1.0\n",
      "term_frequency [ 0  0  0 ... 30 30 29]\n",
      "tok_idx [   3    4    5 ... 5842 5843 5844]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bdSIGA8sWMUs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model = LDA2Vec(n_documents = n_docs, n_document_topics = n_topics,\n",
    "                n_units = n_units, n_vocab = n_vocab, counts = term_frequency,\n",
    "                n_samples = 15, power = power, temperature = temperature)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YNqCse3xWPC8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "if os.path.exists('lda2vec.hdf5'):\n",
    "    print(\"Reloading from saved\")\n",
    "    serializers.load_hdf5(\"lda2vec.hdf5\", model)\n",
    "    \n",
    "if pretrained:\n",
    "    model.sampler.W.data[:, :] = vectors[:n_vocab, :]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G3aLd2SgWSkk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model.to_gpu()\n",
    "optimizer = O.Adam()\n",
    "optimizer.setup(model)\n",
    "clip = chainer.optimizer.GradientClipping(5.0)\n",
    "optimizer.add_hook(clip)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YmZFZ59EWXom",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "j = 0\n",
    "epoch = 0\n",
    "fraction = batchsize * 1.0 / flattened.shape[0]\n",
    "progress = shelve.open('progress.shelve')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MmxTmZhtWZzt",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "1f2605c0-3840-4c47-eeeb-f23a33c54206"
   },
   "source": [
    "for epoch in range(100):\n",
    "    data = prepare_topics(cuda.to_cpu(model.mixture.weights.W.data).copy(),\n",
    "                          cuda.to_cpu(model.mixture.factors.W.data).copy(),\n",
    "                          cuda.to_cpu(model.sampler.W.data).copy(),\n",
    "                          words)\n",
    "    top_words = print_top_words_per_topic(data)\n",
    "    if j % 100 == 0 and j > 100:\n",
    "        coherence = topic_coherence(top_words)\n",
    "        for j in range(n_topics):\n",
    "            print(j, coherence[(j, 'cv')])\n",
    "        kw = dict(top_words=top_words, coherence=coherence, epoch=epoch)\n",
    "        progress[str(epoch)] = pickle.dumps(kw)\n",
    "    data['doc_lengths'] = doc_lengths\n",
    "    data['term_frequency'] = term_frequency\n",
    "    np.savez('topics.pyldavis', **data)\n",
    "    print(epoch)\n",
    "    for d, f in utils.chunks(batchsize, doc_ids, flattened):\n",
    "        t0 = time.time()\n",
    "        model.cleargrads()\n",
    "        #optimizer.use_cleargrads(use=False)\n",
    "        l = model.fit_partial(d.copy(), f.copy())\n",
    "        if(j%500==0):\n",
    "          print(\"after partial fitting:\", l)\n",
    "        prior = model.prior()\n",
    "        loss = prior * fraction\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        msg = (\"J:{j:05d} E:{epoch:05d} L:{loss:1.3e} \"\n",
    "               \"P:{prior:1.3e} R:{rate:1.3e}\")\n",
    "        prior.to_cpu()\n",
    "        loss.to_cpu()\n",
    "        t1 = time.time()\n",
    "        dt = t1 - t0\n",
    "        rate = batchsize / dt\n",
    "        logs = dict(loss=float(l), epoch=epoch, j=j,\n",
    "                    prior=float(prior.data), rate=rate)\n",
    "        if(j%500==0):\n",
    "          print(msg.format(**logs))\n",
    "        j += 1\n",
    "    serializers.save_hdf5(\"lda2vec.hdf5\", model)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Top words in topic 0 <SKIP> ide scsi megs windows meg card pc ram /\n",
      "Top words in topic 1 sharks <SKIP> njd nhl ahl season games mvp league standings\n",
      "Top words in topic 2 ripem encryption pgp <SKIP> ciphertext pem patent cipher cryptanalysis classified\n",
      "Top words in topic 3 soldiers armenians refugees sharks armenian <SKIP> helicopter inhabitants agdam azeri\n",
      "Top words in topic 4 sharks <SKIP> nhl innings goalie team scored players games leafs\n",
      "Top words in topic 5 <SKIP> scsi ide megs meg card turbo drives ram sony\n",
      "Top words in topic 6 <SKIP> bike bikes honda ride ide helmet riding car duo\n",
      "Top words in topic 7 <SKIP> $ 10.00 shipping comics 1 games / 25.00 4\n",
      "Top words in topic 8 <SKIP> islam islamic scholars christians god jesus resurrection jews bible\n",
      "Top words in topic 9 <SKIP> christians god jesus resurrection soldiers davidians that islam islamic\n",
      "Top words in topic 10 <SKIP> that msg christians jail you god i convince we\n",
      "Top words in topic 11 <SKIP> files motif directory interface window xv application widget jpeg\n",
      "Top words in topic 12 <SKIP> ide scsi megs } { meg mydisplay / c650\n",
      "Top words in topic 13 <SKIP> god christians christianity bible belief jesus morality islam christian\n",
      "Top words in topic 14 sharks innings <SKIP> leafs scored goalie nhl players scoring jays\n",
      "Top words in topic 15 encryption <SKIP> classified ripem wiretap privacy cryptology cryptanalysis cryptographic escrowed\n",
      "Top words in topic 16 inhabitants empire <SKIP> hiv palestinian israeli ottoman jews political armenian\n",
      "Top words in topic 17 <SKIP> jpl laboratory distributed hiv newsletter administrative proceedings nasa tutorial\n",
      "Top words in topic 18 <SKIP> islamic islam christians jews israel israeli religion god scholars\n",
      "Top words in topic 19 <SKIP> duo scsi c650 ide buying bikes dealer megs bike\n",
      "0\n",
      "after partial fitting: 13727.977\n",
      "J:28500 E:00000 L:1.373e+04 P:-1.509e+06 R:1.843e+04\n",
      "Top words in topic 0 <SKIP> xterm windows fonts duo colour cica truetype font cache\n",
      "Top words in topic 1 njd scorer <SKIP> islanders ahl rangers hawks jersey minnesota hartford\n",
      "Top words in topic 2 ciphertext cipher md5 rsa <SKIP> encrypt sci.crypt plaintext hash ripem\n",
      "Top words in topic 3 turkish <SKIP> yankees armenians cyprus hawks armenian russian team turks\n",
      "Top words in topic 4 yankees hawks <SKIP> baerga team alomar teams hitter season rbi\n",
      "Top words in topic 5 <SKIP> outlet nec cable wire motherboard duo circuit pins adapter\n",
      "Top words in topic 6 <SKIP> bike duo motherboard rear bikes cable battery switched nec\n",
      "Top words in topic 7 <SKIP> $ shipping 1.50 3.00 2.00 1 sale 0 offer\n",
      "Top words in topic 8 god <SKIP> christ sins jewish jesus lord grace islamic palestinian\n",
      "Top words in topic 9 <SKIP> god sins christ grace lord sin sabbath worship jesus\n",
      "Top words in topic 10 <SKIP> pain god i sins you christ husband that n't\n",
      "Top words in topic 11 <SKIP> xterm fonts x font unix motif windows x11 window\n",
      "Top words in topic 12 <SKIP> xterm colour windows duo cica fonts cursor i cache\n",
      "Top words in topic 13 <SKIP> god christ sins sin jesus grace ceremonial worship christians\n",
      "Top words in topic 14 yankees hawks alomar baerga <SKIP> team hitter rbi detroit orioles\n",
      "Top words in topic 15 <SKIP> cipher cryptographic rsa encryption des key crypto md5 algorithm\n",
      "Top words in topic 16 palestinian militia turkish population government <SKIP> firearms asala extermination territory\n",
      "Top words in topic 17 astronomical jpl <SKIP> astronomy planetary cdc nasa propulsion interactive satellite\n",
      "Top words in topic 18 <SKIP> god sins christ palestinian islamic jewish israeli church lord\n",
      "Top words in topic 19 <SKIP> outlet duo wire circuits nec circuit outlets motherboard fuse\n",
      "1\n",
      "after partial fitting: 13674.773\n",
      "J:29000 E:00001 L:1.367e+04 P:-1.525e+06 R:2.658e+04\n",
      "Top words in topic 0 <SKIP> scsi scsi-1 ide scsi-2 video card windows controller fpu\n",
      "Top words in topic 1 season team <SKIP> hockey njd captain dodgers lindros jets sharks\n",
      "Top words in topic 2 ripem pgp ciphertext rsa anonymity nsa <SKIP> cryptosystem cipher pem\n",
      "Top words in topic 3 dodgers season <SKIP> team azerbaijan sharks score braves karabakh hit\n",
      "Top words in topic 4 season dodgers team score <SKIP> braves sharks teams hockey pens\n",
      "Top words in topic 5 <SKIP> video vertical scsi card controller specs supply $ plastic\n",
      "Top words in topic 6 <SKIP> bike torque battery duo scsi motherboard sho ide dealer\n",
      "Top words in topic 7 <SKIP> $ obo 10.00 20.00 comics 1 / 2 sale\n",
      "Top words in topic 8 <SKIP> bible god israel romans judaism greek jesus christian islam\n",
      "Top words in topic 9 <SKIP> gay heaven arguing god she believe we himself that\n",
      "Top words in topic 10 <SKIP> she you that we they believe arguing senses my\n",
      "Top words in topic 11 <SKIP> motif file files user xlib window servers graphics scsi-1\n",
      "Top words in topic 12 <SKIP> scsi ide scsi-1 scsi-2 card fpu controller / mode\n",
      "Top words in topic 13 <SKIP> bible god darren arrogant faith senses belief beliefs heaven\n",
      "Top words in topic 14 dodgers season braves score team pens hit yankees inning sharks\n",
      "Top words in topic 15 <SKIP> nsa encryption ripem escrow privacy crypto rsa cryptographic ciphertext\n",
      "Top words in topic 16 militia <SKIP> constitution amendment hiv israeli turkish united palestinian adl\n",
      "Top words in topic 17 <SKIP> satellite sensing cdc space launch jpl astronomy nasa hicnet\n",
      "Top words in topic 18 <SKIP> israel bible israeli god greek lebanese judaism lebanon christian\n",
      "Top words in topic 19 <SKIP> duo scsi c650 dealer fpu plastic motherboard bike ide\n",
      "2\n",
      "after partial fitting: 13596.337\n",
      "J:29500 E:00002 L:1.360e+04 P:-1.542e+06 R:1.820e+04\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}